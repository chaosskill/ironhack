{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler, StandardScaler, PowerTransformer, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('./data.csv')\n",
    "\n",
    "# database connection\n",
    "import getpass\n",
    "password = getpass.getpass()\n",
    "connection_string = 'mysql+pymysql://root:'+password+'@localhost/database'\n",
    "engine = create_engine(connection_string)\n",
    "# Query the database\n",
    "query = '''SELECT * FROM table WHERE x GROUP BY y;'''\n",
    "pd.read_sql(query, engine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning/wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Standardize column names\n",
    "data.columns = data.columns.str.lower().str.strip().str.replace(' ', '_')\n",
    "\n",
    "# Sort columns alphabetically\n",
    "data = data.reindex(sorted(data.columns), axis=1).reset_index(drop=True)\n",
    "\n",
    "# Cast columns to appropriate data types\n",
    "def cast_column(col):\n",
    "    try:\n",
    "        col = col.astype(int)  # Try to cast the column to integer\n",
    "    except ValueError:\n",
    "        try:\n",
    "            col = col.astype(float)  # If it fails, try to cast the column to float\n",
    "        except ValueError:\n",
    "            pass  # If it fails again, leave the column as object\n",
    "    return col\n",
    "\n",
    "default_dtypes = data.dtypes  # Store the default dtypes\n",
    "data = data.apply(cast_column, axis=0)  # Apply the function to each column\n",
    "\n",
    "# Clean data (handle null values)\n",
    "def clean_data(data):\n",
    "    null_perc = data.isnull().sum() / len(data) * 100  # Calculate the percentage of null values in each column\n",
    "    for column in null_perc.index:\n",
    "        if null_perc[column] > 80:  # If the percentage is greater than 80%\n",
    "            data = data.drop(columns=column)  # Drop the column\n",
    "        elif 30 < null_perc[column] <= 80:  # If the percentage is between 30% and 80%\n",
    "            if data[column].dtype != 'object':  # If the column is numeric\n",
    "                data[column] = data[column].fillna(data[column].median())  # Fill the null values with the median of the column\n",
    "            else:  # If the column is categorical\n",
    "                data[column] = data[column].fillna(data[column].mode()[0])  # Fill the null values with the mode of the column\n",
    "        else:  # If the percentage is low, leave the column value as it is\n",
    "            continue\n",
    "    return data\n",
    "\n",
    "data = clean_data(data)  # Clean the dataframe\n",
    "data = data.dropna()  # Drop the remaining null values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numerical and categorical features\n",
    "num_features = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_features = data.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Plot histograms of numerical features to check distributions\n",
    "data[num_features].hist(bins=30, figsize=(14, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot a heatmap for correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data[num_features].corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Feature Engineering (PFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers using the IQR method\n",
    "Q1 = data[num_features].quantile(0.25)\n",
    "Q3 = data[num_features].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "data = data[~((data[num_features] < (Q1 - 1.5 * IQR)) | (data[num_features] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "# Remove outliers with nearest neighbors/wiskers \n",
    "\n",
    "# Replace outliers by a known value/median/mode \n",
    "\n",
    "# High cardinality in categorical features: groupe values in bigger groupes (order by frequency)\n",
    "\n",
    "# Variance threshold method (discard features with low variance)\n",
    "# SelectKBest method (select features with highest relationships with a stat test) \n",
    "# Recursive Feature Elimination (RFE) method (select features from subset of features recursively)\n",
    "# Regularization (Lasso -> L1, Ridge -> L2) method (select features with highest coefficients)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "# Replace 'target' with the name of the target variable\n",
    "X = data.drop(columns=['target'])\n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical encoding (for making categorical values to numerical values)\n",
    "\n",
    "# One-Hot encoding (for nominal features) \n",
    "one_hot_encoder = OneHotEncoder(drop='first') # Drop the first column to avoid multicollinearity/dummy variable trap\n",
    "one_hot_data = one_hot_encoder.fit_transform(data[['column_name']]).toarray()\n",
    "one_hot_columns = one_hot_encoder.get_feature_names_out(['column_name'])\n",
    "one_hot_df = pd.DataFrame(one_hot_data, columns=one_hot_columns)\n",
    "data = data.drop(columns=['column_name'])\n",
    "data = pd.concat([data, one_hot_df], axis=1)\n",
    "\n",
    "# Label encoding (for ordinal features)\n",
    "label_encoder = LabelEncoder()\n",
    "data['column_name'] = label_encoder.fit_transform(data['column_name'])\n",
    "\n",
    "\n",
    "# Numerical transformations (for normalizing skewed distributions)\n",
    "\n",
    "# PowerTransformer (Yeo-Johnson, some values can be negative)\n",
    "num_transformer = PowerTransformer()\n",
    "# Box-Cox transformation (only when values are postive)\n",
    "num_transformer = PowerTransformer(method='box-cox')\n",
    "X_train_num_transformed = num_transformer.fit_transform(X_train[num_features])\n",
    "X_test_num_transformed = num_transformer.transform(X_test[num_features])\n",
    "X_train_num_transformed_df = pd.DataFrame(X_train_num_transformed, columns=num_features)\n",
    "X_test_num_transformed_df = pd.DataFrame(X_test_num_transformed, columns=num_features)\n",
    "\n",
    "# QuantileTransformer (Uniform, otherwise 'gaussian' will generate a better distribution)\n",
    "num_transformer = QuantileTransformer(output_distribution='gaussian')\n",
    "X_train_num_transformed = num_transformer.fit_transform(X_train[num_features])\n",
    "X_test_num_transformed = num_transformer.transform(X_test[num_features])\n",
    "X_train_num_transformed_df = pd.DataFrame(X_train_num_transformed, columns=num_features)\n",
    "X_test_num_transformed_df = pd.DataFrame(X_test_num_transformed, columns=num_features)\n",
    "\n",
    "# Log transformation \n",
    "log_transformer = num_features.apply(np.log) \n",
    "X_train_num_transformed = np.log(X_train + 1) # Add 1 to avoid log(0)\n",
    "X_test_num_transformed = np.log(X_test + 1)\n",
    "\n",
    "# Scaling (to get values on the same scale/range)\n",
    "\n",
    "# StandardScaler \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_num_transformed)\n",
    "X_test_scaled = scaler.transform(X_test_num_transformed)\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=num_features)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=num_features)\n",
    "\n",
    "# MinMaxScaler (0 to 1)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_num_transformed)\n",
    "X_test_scaled = scaler.transform(X_test_num_transformed)\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=num_features)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=num_features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate transformed numerical and encoded categorical features if needed\n",
    "X_train = np.concatenate((X_train_scaled, X_train[cat_features]), axis=1)\n",
    "X_test = np.concatenate((X_test_scaled, X_test[cat_features]), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting and scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression \n",
    "# Linear regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train_scaled, y_train)\n",
    "y_pred = reg.predict(X_test_scaled)\n",
    "\n",
    "# K-NN (K-Nearest Neighbors) regression\n",
    "reg = KNeighborsRegressor(n_neighbors=5)\n",
    "# K value is trial and error (Elbow method) can be used to find the best K value, with 5 being the default\n",
    "# Euclidean (default) / Manhattan (distance=1) / Minkowski distance can be used\n",
    "knn_models = []\n",
    "scores = []\n",
    "for k in range(2,15):\n",
    "    model = KNeighborsRegressor(n_neighbors=k)\n",
    "    model.fit(X_train, y_train)\n",
    "    knn_models.append(model)\n",
    "    scores.append(model.score(X_test, y_test))\n",
    "for index,score in enumerate(scores):\n",
    "    print(\"R2 of k-nn model with {} neighbours on TEST set was: {:.2f}\".format(index+2,score))\n",
    "\n",
    "# Regression scores\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"R^2 score: {r2:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification\n",
    "clf = LogisticRegression() # for multiclass classification, use LogisticRegression(multi_class='multinomial')\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# In case of imbalanced classes, use SMOTE to oversample the minority class\n",
    "smote = SMOTE(k_neighbors=5, random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "# In case of imbalanced classes, use RandomUnderSampler to undersample the majority class\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_under, y_train_under = rus.fit_resample(X_train_num_scaled_df, y_train)\n",
    "\n",
    "# K-NN (K-Nearest Neighbors) \n",
    "reg = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Classification scores\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.2f}\")\n",
    "print(f\"Precision: {prec:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Cohen's Kappa: {kappa:.2f}\")\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion_matrix(y_test,y_pred)\n",
    "# Visualize confusion matrix \n",
    "labels = np.array([['TN', 'FP'], ['FN', 'TP']])\n",
    "annot = np.empty_like(cm).astype(str)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        annot[i, j] = f'{labels[i, j]}\\n{cm[i, j]}'\n",
    "\n",
    "\n",
    "sns.heatmap(cm, annot=annot, fmt='', cmap='coolwarm', cbar=False)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance \n",
    "coef_list = list(zip(X_train_scaled.columns, lrclassifier.coef_[0]))\n",
    "coef_df = pd.DataFrame(coef_list, columns=['Feature', 'Coefficient'])\n",
    "coef_df_sorted = coef_df.sort_values(by='Coefficient', ascending=False)\n",
    "print(coef_df_sorted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model and transformers/encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for later use (avoid rerunning) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis testing\n",
    "# H0, null hypothesis (basis assumption we want to validate/reject)\n",
    "# H1, alternative hypothesis\n",
    "# p-value, probability of getting the observed result if the null hypothesis is true \n",
    "# alpha, significance level (0.05, 0.01, 0.001) / 1 - confidence level (95%, 99%, 99.9%)\n",
    "# If p-value < alpha, reject the null hypothesis \n",
    "# If p-value > alpha, fail to reject the null hypothesis\n",
    "    # Second approach for testing:\n",
    "    # compute test statistic from sample and compare to critical value\n",
    "    # if test statistic is greater than critical value, reject the null hypothesis\n",
    "    # if test statistic is less than critical value, fail to reject the null hypothesis\n",
    "\n",
    "# Steps: \n",
    "# Fix the significance level (alpha)\n",
    "# compute the test statistic\n",
    "# compute the critical value of the test's distribution\n",
    "# if test statistic is in the allowed region (size of allowed region is determined by the confidence level, whereas the location of rejection region is determined by the alternative hypothesis), accept the H0, otherwise reject. \n",
    "# The allowed region depends on the type of test \n",
    "\n",
    "\n",
    "# Statistics scoring \n",
    "# Chi-2 (chi-squared) test (test for independence)\n",
    "# t-student test (t-test) (test for difference in means) Good for sample size is less than 30\n",
    "# \n",
    "\n",
    "# One tailed test (H1: mean > 0) / Two tailed test (H1: mean != 0)\n",
    "# Two sample t-test (H0: mean1 = mean2) / Paired t-test (H0: mean1 = mean2)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
